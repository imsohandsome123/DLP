{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab4-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision import transforms,models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils import data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7EiOSFTTtt_",
        "outputId": "357aae82-63f9-4b0f-dd62-35da287ca136"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1MF3UKnX06T",
        "outputId": "5def1d10-572e-4061-b103-77377c3eb7d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vt5DzI72MlRX"
      },
      "outputs": [],
      "source": [
        "\n",
        "def getData(mode):\n",
        "    if mode == 'train':\n",
        "        img = pd.read_csv('train_img.csv', header=None)\n",
        "        label = pd.read_csv('train_label.csv', header=None)\n",
        "        return np.squeeze(img.values), np.squeeze(label.values)\n",
        "    else:\n",
        "        img = pd.read_csv('test_img.csv', header=None)\n",
        "        label = pd.read_csv('test_label.csv', header=None)\n",
        "        return np.squeeze(img.values), np.squeeze(label.values)\n",
        "\n",
        "\n",
        "class RetinopathyLoader(data.Dataset):\n",
        "    def __init__(self, root, mode):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root (string): Root path of the dataset.\n",
        "            mode : Indicate procedure status(training or testing)\n",
        "\n",
        "            self.img_name (string list): String list that store all image names.\n",
        "            self.label (int or float list): Numerical list that store all ground truth label values.\n",
        "        \"\"\"\n",
        "        self.root = root\n",
        "        self.img_name, self.label = getData(mode)\n",
        "        self.mode = mode\n",
        "        self.transformations=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(), transforms.ToTensor(), \n",
        "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        \n",
        "        print(\"> Found %d images...\" % (len(self.img_name)))\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"'return the size of dataset\"\"\"\n",
        "        return len(self.img_name)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"something you should implement here\"\"\"\n",
        "        #step1.\n",
        "        path = os.path.join(self.root, 'data', self.img_name[index]+'.jpeg')\n",
        "        #path = self.root + self.img_name[index] + '.jpeg'\n",
        "        img = Image.open(path).convert('RGB')\n",
        "\n",
        "        #step2.\n",
        "        label = self.label[index]\n",
        "        \n",
        "        #step3.\n",
        "        img=self.transformations(img)\n",
        "        \n",
        "        #step4.\n",
        "        return img, label\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(nn.Module):\n",
        "    def __init__(self,num_class,pretrained=False):\n",
        "        super(ResNet18,self).__init__()\n",
        "        self.model=models.resnet18(pretrained=pretrained)\n",
        "        num=self.model.fc.in_features #the number of inputs for your linear layer\n",
        "        self.model.fc=nn.Linear(num,num_class)\n",
        "        \n",
        "    def forward(self,X):\n",
        "        out=self.model(X)\n",
        "        return out"
      ],
      "metadata": {
        "id": "mMciTej7c7SI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet50(nn.Module):\n",
        "    def __init__(self,num_class,pretrained=False):\n",
        "        super(ResNet50,self).__init__()\n",
        "        self.model=models.resnet18(pretrained=pretrained)\n",
        "        num=self.model.fc.in_features #the number of inputs for your linear layer\n",
        "        self.model.fc=nn.Linear(num,num_class)\n",
        "        \n",
        "    def forward(self,X):\n",
        "        out=self.model(X)\n",
        "        return out"
      ],
      "metadata": {
        "id": "aivB0dWUvHQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,loader_train,loader_test,Loss,optimizer,epochs,device,num_class,name):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        model: resnet model\n",
        "        loader_train: training dataloader\n",
        "        loader_test: testing dataloader\n",
        "        Loss: loss function\n",
        "        optimizer: optimizer\n",
        "        epochs: number of training epoch\n",
        "        device: gpu/cpu\n",
        "        num_class: #target class\n",
        "        name: model name when saving model\n",
        "    Returns:\n",
        "        dataframe: with column 'epoch','acc_train','acc_test'\n",
        "    \"\"\"\n",
        "    df=pd.DataFrame()\n",
        "    df['epoch']=range(1,epochs+1)\n",
        "    best_model_wts=None\n",
        "    best_evaluated_acc=0\n",
        "    \n",
        "    model.to(device)\n",
        "    acc_train=list()\n",
        "    acc_test=list()\n",
        "    for epoch in range(1,epochs+1):\n",
        "        \"\"\"\n",
        "        train\n",
        "        \"\"\"\n",
        "        with torch.set_grad_enabled(True):\n",
        "            model.train()\n",
        "            total_loss=0\n",
        "            correct=0\n",
        "            for images,targets in loader_train:\n",
        "                images,targets=images.to(device),targets.to(device,dtype=torch.long)\n",
        "                predict=model(images)\n",
        "                loss=Loss(predict,targets)\n",
        "                total_loss+=loss.item()\n",
        "                correct+=predict.max(dim=1)[1].eq(targets).sum().item()\n",
        "                \"\"\"\n",
        "                update\n",
        "                \"\"\"\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()  # bp\n",
        "                optimizer.step()\n",
        "            total_loss/=len(loader_train.dataset)\n",
        "            acc=100.*correct/len(loader_train.dataset)\n",
        "            acc_train.append(acc)\n",
        "            print(f'epoch{epoch:>2d} loss:{total_loss:.4f} acc:{acc:.2f}%')\n",
        "        \"\"\"\n",
        "        evaluate\n",
        "        \"\"\"\n",
        "        _,acc=evaluate(model,loader_test,device,num_class)\n",
        "        acc_test.append(acc)\n",
        "        # update best_model_wts\n",
        "        if acc>best_evaluated_acc:\n",
        "            best_evaluated_acc=acc\n",
        "            best_model_wts=copy.deepcopy(model.state_dict())\n",
        "    \n",
        "    df['acc_train']=acc_train\n",
        "    df['acc_test']=acc_test\n",
        "    \n",
        "    # save model\n",
        "    torch.save(best_model_wts,os.path.join('models',name+'.pt'))\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "WOvetpVdvOk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model,loader_test,device,num_class):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        model: resnet model\n",
        "        loader_test: testing dataloader\n",
        "        device: gpu/cpu\n",
        "        num_class: #target class\n",
        "    Returns:\n",
        "        confusion_matrix: (num_class,num_class) ndarray\n",
        "        acc: accuracy rate\n",
        "    \"\"\"\n",
        "    confusion_matrix=np.zeros((num_class,num_class))\n",
        "    \n",
        "    with torch.set_grad_enabled(False):\n",
        "        model.eval()\n",
        "        correct=0\n",
        "        for images,targets in loader_test:  \n",
        "            images,targets=images.to(device),targets.to(device,dtype=torch.long)\n",
        "            predict=model(images)\n",
        "            predict_class=predict.max(dim=1)[1]\n",
        "            correct+=predict_class.eq(targets).sum().item()\n",
        "            for i in range(len(targets)):\n",
        "                confusion_matrix[int(targets[i])][int(predict_class[i])]+=1\n",
        "        acc=100.*correct/len(loader_test.dataset)\n",
        "        \n",
        "    # normalize confusion_matrix\n",
        "    confusion_matrix=confusion_matrix/confusion_matrix.sum(axis=1).reshape(num_class,1)\n",
        "    \n",
        "    return confusion_matrix,acc"
      ],
      "metadata": {
        "id": "Zr3TJSLv1_Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(dataframe1,dataframe2,title):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "        dataframe1: dataframe with 'epoch','acc_train','acc_test' columns of without pretrained weights model \n",
        "        dataframe2: dataframe with 'epoch','acc_train','acc_test' columns of with pretrained weights model \n",
        "        title: figure's title\n",
        "    Returns:\n",
        "        figure: an figure\n",
        "    \"\"\"\n",
        "    fig=plt.figure(figsize=(10,6))\n",
        "    for name in dataframe1.columns[1:]:\n",
        "        plt.plot(range(1,1+len(dataframe1)),name,data=dataframe1,label=name[4:]+'(w/o pretraining)')\n",
        "    for name in dataframe2.columns[1:]:\n",
        "        plt.plot(range(1,1+len(dataframe2)),name,data=dataframe2,label=name[4:]+'(with pretraining)')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy(%)')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    return fig\n",
        "\n",
        "def plot_confusion_matrix(confusion_matrix):\n",
        "    fig, ax = plt.subplots(figsize=(6,6))\n",
        "    ax.matshow(confusion_matrix, cmap=plt.cm.Blues)\n",
        "    ax.xaxis.set_label_position('top')\n",
        "    for i in range(confusion_matrix.shape[0]):\n",
        "        for j in range(confusion_matrix.shape[1]):\n",
        "            ax.text(i, j, '{:.2f}'.format(confusion_matrix[j, i]), va='center', ha='center')\n",
        "    ax.set_xlabel('Predicted label')\n",
        "    ax.set_ylabel('True label')\n",
        "    return fig"
      ],
      "metadata": {
        "id": "1IAAU6MTMyRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters"
      ],
      "metadata": {
        "id": "89dwmODfM18G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_class=5\n",
        "batch_size=64\n",
        "lr=1e-3\n",
        "epochs=10\n",
        "momentum=0.9\n",
        "weight_decay=5e-4\n",
        "Loss=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "JzRp-lKfM1Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train=RetinopathyLoader('','train')\n",
        "loader_train=DataLoader(dataset=dataset_train,batch_size=batch_size,shuffle=True,num_workers=4)\n",
        "\n",
        "dataset_test=RetinopathyLoader('','test')\n",
        "loader_test=DataLoader(dataset=dataset_test,batch_size=batch_size,shuffle=False,num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMOg_SmEXVpr",
        "outputId": "3f344d5e-fd38-4c2c-e671-4dddb706ae48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Found 28100 images...\n",
            "> Found 7026 images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet18"
      ],
      "metadata": {
        "id": "30OpBxwdOWAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "#resnet18 without pretrained weights\n",
        "model_wo=ResNet18(num_class=num_class,pretrained=False)\n",
        "optimizer=optim.SGD(model_wo.parameters(),lr=lr,momentum=momentum,weight_decay=weight_decay)\n",
        "df_wo_pretrained=train(model_wo,loader_train,loader_test,Loss,optimizer,epochs,device,num_class,'resnet18_wo_pretraining')\n",
        "# test and save confusion matrix figure\n",
        "confusion_matrix,_=evaluate(model_wo,loader_test,device,num_class)\n",
        "figure=plot_confusion_matrix(confusion_matrix)\n",
        "figure.savefig('ResNet18 (wo pretrained weights).png')\n",
        "\"\"\"\n",
        "#resnet18 with pretrained weights\n",
        "model_with=ResNet18(num_class=num_class,pretrained=True)\n",
        "optimizer=optim.SGD(model_with.parameters(),lr=lr,momentum=momentum,weight_decay=weight_decay)\n",
        "df_with_pretrained=train(model_with,loader_train,loader_test,Loss,optimizer,epochs,device,num_class,'resnet18_with_pretraining')\n",
        "# test and get a confusion matrix\n",
        "confusion_matrix,_=evaluate(model_with,loader_test,device,num_class)\n",
        "figure=plot_confusion_matrix(confusion_matrix)\n",
        "figure.savefig('ResNet18 (with pretrained weights).png')\n",
        "\n",
        "#plot accuracy figure\n",
        "figure=plot(df_wo_pretrained,df_with_pretrained,'Result Comparison(ResNet18)')\n",
        "figure.savefig('Result Comparison(ResNet18).png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "adXCOErrN8wc",
        "outputId": "1ccfea0b-d61c-4c09-d346-2fab987f5966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 loss:0.0123 acc:74.36%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5b6ccb9bc192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel_with\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mResNet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_with\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdf_with_pretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_with\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloader_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLoss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'resnet18_with_pretraining'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m# test and get a confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_with\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloader_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-f14e7a35f0f1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader_train, loader_test, Loss, optimizer, epochs, device, num_class, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mcorrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_wo_pretrained)\n",
        "print(df_with_pretrained)"
      ],
      "metadata": {
        "id": "BoEai805OMa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet50"
      ],
      "metadata": {
        "id": "nlGSKCmcOZAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=16\n",
        "epochs=5\n",
        "dataset_train=RetinopathyLoader('','train')\n",
        "loader_train=DataLoader(dataset=dataset_train,batch_size=batch_size,shuffle=True,num_workers=4)\n",
        "\n",
        "dataset_test=RetinopathyLoader('','test')\n",
        "loader_test=DataLoader(dataset=dataset_test,batch_size=batch_size,shuffle=False,num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYI3E3mhOMfc",
        "outputId": "1c914b66-71ad-4e6e-d363-218fa99e4acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Found 28100 images...\n",
            "> Found 7026 images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "#resnet50 without pretrained weights\n",
        "model_wo=ResNet50(num_class=num_class,pretrained=False)\n",
        "optimizer=optim.SGD(model_wo.parameters(),lr=lr,momentum=momentum,weight_decay=weight_decay)\n",
        "df_wo_pretrained=train(model_wo,loader_train,loader_test,Loss,optimizer,epochs,device,num_class,'resnet50_wo_pretraining')\n",
        "# test and save confusion matrix figure\n",
        "confusion_matrix,_=evaluate(model_wo,loader_test,device,num_class)\n",
        "figure=plot_confusion_matrix(confusion_matrix)\n",
        "figure.savefig('ResNet50 (wo pretrained weights).png')\n",
        "\"\"\"\n",
        "#resnet50 with pretrained weights\n",
        "model_with=ResNet50(num_class=num_class,pretrained=True)\n",
        "optimizer=optim.SGD(model_with.parameters(),lr=lr,momentum=momentum,weight_decay=weight_decay)\n",
        "df_with_pretrained=train(model_with,loader_train,loader_test,Loss,optimizer,epochs,device,num_class,'resnet50_with_pretraining')\n",
        "# test and get a confusion matrix\n",
        "confusion_matrix,_=evaluate(model_with,loader_test,device,num_class)\n",
        "figure=plot_confusion_matrix(confusion_matrix)\n",
        "figure.savefig('ResNet50 (with pretrained weights).png')\n",
        "\n",
        "#plot accuracy figure\n",
        "figure=plot(df_wo_pretrained,df_with_pretrained,'Result Comparison(ResNet50)')\n",
        "figure.savefig('Result Comparison(ResNet50).png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibAMWqi6OOUm",
        "outputId": "231d7917-2728-469a-8cd2-eba7daba83eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 loss:0.0463 acc:75.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_wo_pretrained)\n",
        "print(df_with_pretrained)"
      ],
      "metadata": {
        "id": "Hl_gZS5rOPqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=[[1,75.886121,78.152576],[2,78.978648,80.173641],[3,80.103203,78.921150],[4,80.911032,80.885283],[5,81.459075,80.970680]]\n",
        "print(pd.DataFrame(df, columns = ['epoch','acc_train','acc_test']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Xg4yAXL4SWT",
        "outputId": "81ca5ec5-7e7a-40ce-a34e-6b53529e9ea3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   epoch  acc_train   acc_test\n",
            "0      1  75.886121  78.152576\n",
            "1      2  78.978648  80.173641\n",
            "2      3  80.103203  78.921150\n",
            "3      4  80.911032  80.885283\n",
            "4      5  81.459075  80.970680\n"
          ]
        }
      ]
    }
  ]
}